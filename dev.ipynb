{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from local_test import load_validation_data\n",
    "import random\n",
    "\n",
    "data = load_validation_data(\"t2t_val.jsonl\")\n",
    "idx = random.randint(0, len(data) - 1)\n",
    "item = data[idx]\n",
    "query = item[\"query\"]\n",
    "iid = item[\"iid\"]\n",
    "print(item)\n",
    "# report = run_rag_static(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c44ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "from vllm import LLM\n",
    "\n",
    "# Sample prompts.\n",
    "text_1 = \"What is the capital of France?\"\n",
    "texts_2 = [\"The capital of Brazil is Brasilia.\", \"The capital of France is Paris.\"]\n",
    "\n",
    "# Create an LLM.\n",
    "# You should pass task=\"score\" for cross-encoder models\n",
    "model = LLM(\n",
    "    model=\"BAAI/bge-reranker-v2-m3\",\n",
    "    task=\"score\",\n",
    "    enforce_eager=True,\n",
    ")\n",
    "\n",
    "# Generate scores. The output is a list of ScoringRequestOutputs.\n",
    "outputs = model.score(text_1, texts_2)\n",
    "\n",
    "# Print the outputs.\n",
    "for text_2, output in zip(texts_2, outputs):\n",
    "    score = output.outputs.score\n",
    "    print(f\"Pair: {[text_1, text_2]!r} | Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c81acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0\n",
    "# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\n",
    "# ruff: noqa: E501\n",
    "# %pip install vllm\n",
    "from vllm import LLM\n",
    "\n",
    "model_name = \"Qwen/Qwen3-Reranker-0.6B\"\n",
    "\n",
    "# What is the difference between the official original version and one\n",
    "# that has been converted into a sequence classification model?\n",
    "# Qwen3-Reranker is a language model that doing reranker by using the\n",
    "# logits of \"no\" and \"yes\" tokens.\n",
    "# It needs to computing 151669 tokens logits, making this method extremely\n",
    "# inefficient, not to mention incompatible with the vllm score API.\n",
    "# A method for converting the original model into a sequence classification\n",
    "# model was proposed. Seeï¼šhttps://huggingface.co/Qwen/Qwen3-Reranker-0.6B/discussions/3\n",
    "# Models converted offline using this method can not only be more efficient\n",
    "# and support the vllm score API, but also make the init parameters more\n",
    "# concise, for example.\n",
    "# model = LLM(model=\"tomaarsen/Qwen3-Reranker-0.6B-seq-cls\", task=\"score\")\n",
    "\n",
    "# If you want to load the official original version, the init parameters are\n",
    "# as follows.\n",
    "\n",
    "\n",
    "def get_model() -> LLM:\n",
    "    \"\"\"Initializes and returns the LLM model for Qwen3-Reranker.\"\"\"\n",
    "    return LLM(\n",
    "        model=model_name,\n",
    "        task=\"score\",\n",
    "        hf_overrides={\n",
    "            \"architectures\": [\"Qwen3ForSequenceClassification\"],\n",
    "            \"classifier_from_token\": [\"no\", \"yes\"],\n",
    "            \"is_original_qwen3_reranker\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "# Why do we need hf_overrides for the official original version:\n",
    "# vllm converts it to Qwen3ForSequenceClassification when loaded for\n",
    "# better performance.\n",
    "# - Firstly, we need using `\"architectures\": [\"Qwen3ForSequenceClassification\"],`\n",
    "# to manually route to Qwen3ForSequenceClassification.\n",
    "# - Then, we will extract the vector corresponding to classifier_from_token\n",
    "# from lm_head using `\"classifier_from_token\": [\"no\", \"yes\"]`.\n",
    "# - Third, we will convert these two vectors into one vector.  The use of\n",
    "# conversion logic is controlled by `using \"is_original_qwen3_reranker\": True`.\n",
    "\n",
    "# Please use the query_template and document_template to format the query and\n",
    "# document for better reranker results.\n",
    "\n",
    "prefix = '<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \"yes\" or \"no\".<|im_end|>\\n<|im_start|>user\\n'\n",
    "suffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "\n",
    "query_template = \"{prefix}<Instruct>: {instruction}\\n<Query>: {query}\\n\"\n",
    "document_template = \"<Document>: {doc}{suffix}\"\n",
    "\n",
    "\n",
    "instruction = (\n",
    "    \"Given a web search query, retrieve relevant passages that answer the query\"\n",
    ")\n",
    "\n",
    "queries = [\n",
    "    \"What is the capital of China?\",\n",
    "    \"Explain gravity\",\n",
    "]\n",
    "\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\",\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    query_template.format(prefix=prefix, instruction=instruction, query=query)\n",
    "    for query in queries\n",
    "]\n",
    "documents = [document_template.format(doc=doc, suffix=suffix) for doc in documents]\n",
    "\n",
    "# model = get_model()\n",
    "model = LLM(\n",
    "    model=\"tomaarsen/Qwen3-Reranker-0.6B-seq-cls\",\n",
    "    task=\"score\",\n",
    "    max_model_len=512,\n",
    "    gpu_memory_utilization=0.1,\n",
    ")\n",
    "# outputs = model.score(queries, documents)\n",
    "\n",
    "# print(\"-\" * 30)\n",
    "# print([output.outputs.score for output in outputs])\n",
    "# print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\",\n",
    "    \"It's very dark and high pressure\",\n",
    "    \"The bottom if mariana trench is very interesting\",\n",
    "]\n",
    "outputs = model.score(\"What is in the mariana trench\", documents)\n",
    "scores = [output.outputs.score for output in outputs]\n",
    "idxs = sorted(range(len(scores)), key=lambda i: scores[i], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0b848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [output.outputs.score for output in outputs]\n",
    "idxs = sorted(range(len(scores)), key=lambda i: scores[i], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b553d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retriever import retrieve\n",
    "\n",
    "out = retrieve(\"How far is the sun from earth\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92980e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b54d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c35c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3b5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
